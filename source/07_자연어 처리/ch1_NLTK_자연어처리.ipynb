{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e380e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:90%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:10pt;}\n",
       "div.text_cell_render.rendered_html{font-size:11pt;}\n",
       "div.output {font-size:10pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:10pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:10pt;padding:5px;}\n",
       "table.dataframe{font-size:10px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:90%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:10pt;}\n",
    "div.text_cell_render.rendered_html{font-size:11pt;}\n",
    "div.output {font-size:10pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:10pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:10pt;padding:5px;}\n",
    "table.dataframe{font-size:10px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ba528",
   "metadata": {},
   "source": [
    "<b><font size=\"6\" color=\"red\">Ch.1 NLTK 자연어 처리 패키지</font><b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9ba77",
   "metadata": {},
   "source": [
    "```\n",
    "자연어 처리 : 텍스트전처리, 단어의 빈도수 측정, 문서유사도 측정, 연관 분석, 딥러닝, \n",
    "            워드임베딩, 텍스트 분류, [생성형AI ... (LLM 학습에서 하자]\n",
    "```\n",
    "\n",
    "# 1. NLTK 패키지\n",
    "- 텍스트 전처리 : 토큰화(문장, 어절, 형태소), 정규표현식을 이용해 불용어 처리, 어간 추출\n",
    "- 품사 태깅 : 단어별 품사를 식별\n",
    "- 어휘 데이터베이스 사용\n",
    "- pip install nltk==3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e173a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f926f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 다운로드 받을 폴더 (아래가 아니면 인식 못함)\n",
    "# c:/nltk_data\n",
    "# c:/Users/내컴퓨터이름/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/share/nltk_data\n",
    "# c:/Users/내컴퓨터이름/anaconda3/lib/nltk_data\n",
    "# c:/Users/내컴퓨터이름/AppData/Roaming/nltk_data\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec0018a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 리스트\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6297970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n"
     ]
    }
   ],
   "source": [
    "# 제인 오스틴 소설 에마 텍스트 데이터셋\n",
    "emma = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "print(emma[:36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb68170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, 887071)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emma), len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684f3178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 수:  7456\n",
      "'[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.'\n"
     ]
    }
   ],
   "source": [
    "# sent_tokenize() : 문장 단위로 쪼갠 list 반환\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokens = sent_tokenize(emma)\n",
    "print('문장 수: ', len(sent_tokens))\n",
    "print(\"%r\" % sent_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "197905bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "# word_tokenize() : 단어 단위로 쪼갠 list 반환\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(sent_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b605936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1816', '8', '23', '28', '28', '24', '7', '10', '000', '10', '000', '26']\n",
      "['Emma', 'by', 'Jane', 'Austen', '1816', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her']\n"
     ]
    }
   ],
   "source": [
    "# RegexpTokenizer 클래스 : 토큰화할 때 정규표현식\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "ret = RegexpTokenizer('\\d+') # 숫자만 뽑아 보기 (\\d = 0~9)\n",
    "digits = ret.tokenize(emma)\n",
    "print(digits)\n",
    "ret1 = RegexpTokenizer('\\w+') #영문자, 숫자, '_'만 포함 (= [a-zA-Z0-9_])\n",
    "words = ret1.tokenize(sent_tokens[0])\n",
    "#ret1 = RegexpTokenizer('[a-zA-Z]+') #영문자만 포함\n",
    "#words = ret1.tokenize(sent_tokens[0])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6376b9",
   "metadata": {},
   "source": [
    "# 2. 형태소(의미를 지닌 가장 작은 단위) 분석\n",
    "- 형태소는 조사도 포함. 하지만 자연어 처리에선 거진 조사 포함하지 않는다.\n",
    "- cf. 자연어 처리의 기본은 형태소 분석과 품사 태깅 - 어간 추출(Stemming), 품사 태깅(PosTagging)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1ad5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'file', 'live', 'cri', 'warn', 'die']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['sending', 'cooking', 'files', 'lives', 'crying', 'warned', 'dying']\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, RegexpStemmer\n",
    "# 어간 추출 1 : PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "[pst.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40a30673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'fil', 'liv', 'cry', 'warn', 'dying']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출 2 : LancasterStemmer # 가장 많이 쓴다 그러네\n",
    "lst = LancasterStemmer()\n",
    "[lst.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ff94f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send', 'cook', 'files', 'lives', 'cry', 'warned', 'dy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어간 추출 3 : RegexpStemmer\n",
    "rst = RegexpStemmer('ing')\n",
    "[rst.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56c98f",
   "metadata": {},
   "source": [
    "# 3. 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a232418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사태깅할 내용:  ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.']\n",
      "품사태깅 결과:  [('[', 'NNS'), ('Emma', 'NNP'), ('by', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), (']', 'NNP'), ('VOLUME', 'NNP'), ('I', 'PRP'), ('CHAPTER', 'VBP'), ('I', 'PRP'), ('Emma', 'NNP'), ('Woodhouse', 'NNP'), (',', ','), ('handsome', 'NN'), (',', ','), ('clever', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ'), (',', ','), ('with', 'IN'), ('a', 'DT'), ('comfortable', 'JJ'), ('home', 'NN'), ('and', 'CC'), ('happy', 'JJ'), ('disposition', 'NN'), (',', ','), ('seemed', 'VBD'), ('to', 'TO'), ('unite', 'VB'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('blessings', 'NNS'), ('of', 'IN'), ('existence', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), ('lived', 'VBN'), ('nearly', 'RB'), ('twenty-one', 'CD'), ('years', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('with', 'IN'), ('very', 'RB'), ('little', 'JJ'), ('to', 'TO'), ('distress', 'VB'), ('or', 'CC'), ('vex', 'VB'), ('her', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print('품사태깅할 내용: ', word_tokenize(sent_tokens[0]))\n",
    "from nltk.tag import pos_tag\n",
    "tagged_list = pos_tag(word_tokenize(sent_tokens[0]))\n",
    "print('품사태깅 결과: ', tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2075ebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'Jane', 'Austen', ']', 'VOLUME', 'Emma', 'Woodhouse', 'handsome', 'clever', 'home', 'disposition', 'blessings', 'existence', 'years', 'world']\n"
     ]
    }
   ],
   "source": [
    "# 명사만 추출 : NN, NNS, NNP, NNPS\n",
    "nouns_list = []\n",
    "for word, tag in tagged_list:\n",
    "#    if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "    if tag.find('NN') != -1:\n",
    "        nouns_list.append(word)\n",
    "print(nouns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c7d1805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'Jane', 'Austen', ']', 'VOLUME', 'Emma', 'Woodhouse', 'handsome', 'clever', 'home', 'disposition', 'blessings', 'existence', 'years', 'world']\n"
     ]
    }
   ],
   "source": [
    "nouns_list = [word for word, tag in tagged_list if tag in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "print(nouns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85c59b",
   "metadata": {},
   "source": [
    "## Quiz. Emma 소설에서\n",
    "1. 특수문자가 들어가지 않은 3글자 이상의 단어만 추출 : RegexpTokenizer\n",
    "2. \"Emma\"가 몇 번 등장했는지, 품사 태깅이 어떤 품사들로 되어 있는지(set) 모두 출력\n",
    "3. 내가 원하는 품사(명사, 형용사...)만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf0431b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123877\n",
      "['Emma', 'Jane', 'Austen', '1816', 'VOLUME', 'CHAPTER', 'Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'unite', 'some', 'the', 'best', 'blessings', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty', 'one', 'years', 'the', 'world', 'with', 'very', 'little', 'distress', 'vex', 'her', 'She', 'was', 'the', 'youngest', 'the', 'two', 'daughters', 'most', 'affectionate', 'indulgent']\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "ret = RegexpTokenizer('\\w{3,}')\n",
    "over3words = ret.tokenize(emma)\n",
    "print(len(over3words))\n",
    "print(over3words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72933950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-1.\n",
    "over3words.count('Emma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49991b26",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2-2.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m words \u001b[38;5;241m=\u001b[39m word_tokenize(emma)\n\u001b[1;32m----> 3\u001b[0m tag_list \u001b[38;5;241m=\u001b[39m \u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m tag_list\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "# 2-2.\n",
    "words = word_tokenize(emma)\n",
    "tag_list = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b460f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf56be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053450b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bcb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e2c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcd90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb7738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2292f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c2848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58246d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b40149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4df3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f627abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60107290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f642e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d1a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a807d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109d87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd1dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff6676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6078d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8721028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36009e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31b89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5c5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9e2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecb2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5b562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd214227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp (ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
