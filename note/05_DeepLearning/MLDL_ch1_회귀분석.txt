Ch. 1 ML/DL 입문 - 회귀분석

회귀분석 실습 핵심 요약

TensorFlow를 기반으로 하며, 저수준(Low-level) API와 고수준(High-level) Keras API 두 가지 방식으로 회귀분석을 구현한다.

1. TensorFlow 기초 문법 (Tensor Manipulation)

텐서플로우의 기본 자료구조와 연산.

- 상수와 변수:
    - tf.constant(): 변하지 않는 수(상수)를 정의한다.
    - tf.Variable(): 모델이 학습하면서 업데이트해야 할 가중치(W)와 편향(b)을 정의한다. assign() 메서드로 값을 변경할 수 있다.
- 차원과 연산:
    - tf.shape(): 텐서의 차원(크기)을 확인한다.
    - tf.add, tf.subtract, tf.multiply, tf.divide: 기본 사칙연산 함수를 사용한다.
    - tf.matmul(): 행렬 곱셈(Matrix Multiplication)을 수행한다. (이후 다중 선형 회귀에서 사용됨)
    
    ---
    

2. 단순 선형 회귀 (Simple Linear Regression)

y = Wx + b (입력 1개, 출력 1개) 모델을 두 가지 방식으로 구현한다.

A. Low-level 구현 (TensorFlow 기본 연산 활용)

GradientTape를 사용하지 않고, 옵티마이저의 minimize 기능을 활용해 간결하게 구현된 방식.

- 변수 초기화: W와 b를 tf.Variable을 사용해 임의의 값(랜덤 정규분포 등)으로 초기화한다.
- 가설과 비용:
    - hypothesis = W * x_train + b
    - cost = tf.reduce_mean(tf.square(hypothesis - y_train)) (MSE: 평균 제곱 오차)
- 최적화 (핵심 코드):
    - optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
    - optimizer.minimize(lambda: cost_func, var_list=[W, b])
    - 설명: 비용을 계산하는 로직을 람다(lambda) 함수 등으로 포장하여 minimize에 전달하면, 내부적으로 미분(gradient) 계산과 가중치 업데이트가 동시에 수행된다.

B. High-level 구현 (Keras API 활용)

텐서플로우의 상위 API인 Keras를 사용하여 모델 구조를 추상화한다.

- 모델 정의: tf.keras.Sequential()로 모델 객체를 생성합니다.
- 레이어 추가: model.add(tf.keras.layers.Dense(1, input_dim=1))
    - 입력 차원(input_dim)이 1이고, 출력 뉴런이 1개인 완전 연결 층(Dense)을 추가한다.
- 컴파일: model.compile(loss='mse', optimizer='sgd')
    - 손실 함수로 MSE, 최적화 도구로 SGD를 설정한다.
- 학습: model.fit(x_train, y_train, epochs=...)
    - 데이터를 주입하고 지정된 횟수만큼 반복 학습을 수행한다.

---

3. 다중 선형 회귀 (Multivariate Linear Regression)

입력 변수가 3개(x_1, x_2, x_3)이고 출력이 1개(y)인 경우.

- 데이터 구조: 입력 데이터 x_train이 (5, 3) 형태의 행렬(Matrix)로 정의된다.
- Low-level 구현의 변화:
    - 가설 수식이 W * x + b (스칼라 곱)에서 tf.matmul(X, W) + b (행렬 곱)으로 변경된다.
    - 이에 따라 가중치 W의 차원도 (3, 1) 형태로 초기화된다.
- High-level 구현의 변화:
    - Dense 레이어의 설정이 input_dim=3으로 변경된다. (model.add(tf.keras.layers.Dense(1, input_dim=3)))

---

요약

TensorFlow를 사용하여 텐서 연산을 익힌 후, optimizer.minimize()를 이용한 수동 학습과 Keras의 fit()을 이용한 자동 학습을 대조하며 선형 회귀 모델을 구현.