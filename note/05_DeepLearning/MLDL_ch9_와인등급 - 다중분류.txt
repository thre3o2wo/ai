Ch. 9 다중분류 - Wine Quality 등급 예측

와인의 화학적 특성 데이터를 기반으로 품질 등급(3~8등급)을 예측하는 다중 분류(Multi-class Classification) 문제.

1. 핵심 키워드

- Multi-class Classification (다중 분류): 결과값이 2개(0/1)가 아니라 3개 이상인 경우(여기서는 6개 등급)를 예측하는 문제.
- Stratified Sampling (층화 추출): 데이터를 나눌 때 각 클래스(등급)의 비율을 학습셋과 테스트셋에 동일하게 유지하는 샘플링 방식. 특정 등급 데이터가 적을 때 필수.
- Standard Scaler: 평균이 0, 분산이 1이 되도록 데이터를 변환하여 정규 분포 형태로 만드는 스케일링 기법.
- Callback (콜백): 학습 도중 특정 이벤트(예: 에포크 끝날 때)가 발생하면 자동으로 호출되는 함수. 조기 종료나 모델 저장 등에 사용됨.

2. 주요 개념 및 로직

- 출력층 설계: 와인 등급이 3, 4, 5, 6, 7, 8로 총 6개 클래스이므로, 출력층 노드 수는 6개, 활성화 함수는 Softmax를 사용한다.
- 데이터 인코딩:
    - 타겟 변수(품질)는 숫자로 되어 있지만, 크기 비교보다는 분류가 목적이므로 pd.get_dummies를 사용해 원-핫 인코딩 처리한다.
    - 이에 따라 손실 함수는 categorical_crossentropy를 사용한다.
- 결과 해석: 모델은 0~5 사이의 인덱스를 예측하므로, 실제 등급(3~8)으로 복원하려면 예측 결과에 +3을 더해줘야 한다.

3. 코드의 구성과 흐름

1. 데이터 준비:
    - read_csv로 데이터를 로드하고 value_counts로 등급별 비율 확인(데이터 불균형 존재).
2. 전처리:
    - 독립변수: StandardScaler로 스케일링.
    - 종속변수: get_dummies로 원-핫 인코딩.
    - 분리: train_test_split에서 stratify=Y 옵션을 사용하여 등급 비율을 유지하며 분리.
3. 모델 설계:
    - Input(11) → Dense(50, relu) → Dropout(0.1) → Dense(6, softmax) 구조.
4. 학습 설정 (Callback):
    - EarlyStopping: 성능 개선이 없으면 학습 중단.
    - ModelCheckpoint: 검증 점수가 최고일 때 모델 파일(.h5) 저장.
    - CustomHistory: 에포크마다 로그 출력을 조절하는 사용자 정의 콜백 사용.
5. 평가 및 예측:
    - 학습 곡선(Loss/Acc) 시각화.
    - pd.crosstab을 활용해 실제값과 예측값의 혼동 행렬(Confusion Matrix) 출력.

4. 참고 개념 (심화)

- Dropout: 은닉층의 뉴런 일부를 무작위로 꺼서(0으로 만듦) 학습에 참여시키지 않는 기법. 모델이 특정 뉴런에 과도하게 의존하는 것을 막아 과적합(Overfitting)을 방지한다.